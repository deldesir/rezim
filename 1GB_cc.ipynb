{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b31818dc-dc3c-431d-a573-1c7f5471d310",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/usr/bin/env python3\n",
    "# -*- coding: utf-8 -*-\n",
    "import subprocess\n",
    "from pathlib import Path\n",
    "\n",
    "PROJECT_NAME = \"0223-crashcourse_1GB\"\n",
    "PREFIX = Path.home() / \"zims\"\n",
    "CACHE_DIR = PREFIX / PROJECT_NAME / \"youtube\" / \"cache\"\n",
    "TARGET_SIZE = 1000000000  # 1GB\n",
    "BASE_DIR = PREFIX / PROJECT_NAME\n",
    "WORKING_DIR = PREFIX / PROJECT_NAME / \"working\"\n",
    "PROJECT_DIR = PREFIX / PROJECT_NAME / \"tree\"\n",
    "OUTPUT_DIR = PREFIX / PROJECT_NAME / \"output_tree\"\n",
    "SOURCE_DIR = PREFIX / PROJECT_NAME / \"zim-src\"\n",
    "NEW_ZIM_DIR = PREFIX / PROJECT_NAME / \"new-zim\"\n",
    "PROOF_DIR = PREFIX / PROJECT_NAME / \"proof\"\n",
    "\n",
    "directories = [OUTPUT_DIR, PROJECT_DIR, CACHE_DIR / \"video_json\", SOURCE_DIR, NEW_ZIM_DIR, PROOF_DIR, WORKING_DIR]\n",
    "for directory in directories:\n",
    "    directory.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "source_url = \"/library/zims/content/crashcourse_en_all_2023-02.zim\"\n",
    "\n",
    "try:\n",
    "    ZIM_PATH = (SOURCE_DIR / next(iter(SOURCE_DIR.glob(\"*\")))).resolve()\n",
    "    print(ZIM_PATH)\n",
    "except StopIteration:\n",
    "    if source_url.startswith(\"/library/zims/\"):\n",
    "        (SOURCE_DIR / source_url.split(\"/\")[-1]).symlink_to(source_url)\n",
    "    else:\n",
    "        subprocess.run(f\"wget -P {SOURCE_DIR} {source_url}\", shell=True)\n",
    "        ZIM_PATH = SOURCE_DIR / source_url.split(\"/\")[-1]\n",
    "\n",
    "if not ZIM_PATH.exists():\n",
    "    print(f\"ZIM file at path {ZIM_PATH} not found. Exiting.\")\n",
    "    exit(1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66e79dee-a409-42d9-afe3-95b2fd837124",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'{PREFIX},{PROJECT_DIR}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81d83445-ec52-4c4d-a7cb-299ef2bebbbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# First we need to get a current copy of the script\n",
    "FACTORY_REPO = '/opt/iiab/iiab-factory/'\n",
    "cmd = '/bin/cp %s/content/kiwix/zim-filter/de-namespace.sh %s'%(FACTORY_REPO,PREFIX)\n",
    "subprocess.run(cmd,shell=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2351aac4-3f8b-4590-a616-a047b63744ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The following command will zimdump to the \"tree\" directory\n",
    "#  Despite the name, removing namespaces seems unnecessary, and more complex\n",
    "# It will return without doing anything if the \"tree' is not empty\n",
    "print('Using zimdump to expand the zim file to %s'%BASE_DIR)\n",
    "progname = str(PREFIX) + \"/de-namespace.sh\"\n",
    "cmd = \"%s %s %s\"%(progname,ZIM_PATH, BASE_DIR)\n",
    "print('command:%s'%cmd)\n",
    "subprocess.run(cmd,shell=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bedd820-962f-4bcc-b30f-df06be51997d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# WARNING: Please wait until the script is done running before moving to the next cell \n",
    "# to avoid \"duration name not defined\" error.\n",
    "# Orange hour glass icon in your browser tab means the script is running.\n",
    "\n",
    "# use yt_dlp instead of youtube_dl to avoid the script being \"stopped\" because of age restrictions\n",
    "import os\n",
    "import json\n",
    "from yt_dlp import YoutubeDL\n",
    "ydl_opts = {\n",
    "    'ignoreerrors': True\n",
    "}\n",
    "ydl = YoutubeDL(ydl_opts)\n",
    "print('Downloading metadata from Youtube')\n",
    "downloaded = 0\n",
    "skipped = 0\n",
    "# Create a list of youtube id's\n",
    "yt_id_list = os.listdir(str(PROJECT_DIR) + '/videos/')\n",
    "for yt_id in iter(yt_id_list):\n",
    "    if os.path.exists(str(CACHE_DIR) + '/video_json/' + yt_id + '.json'):\n",
    "        # skip over items that are already downloadd\n",
    "        skipped += 1\n",
    "        continue\n",
    "    with ydl:\n",
    "       result = ydl.extract_info(\n",
    "                'http://www.youtube.com/watch?v=%s'%yt_id,\n",
    "                download=False # We just want to extract the info\n",
    "                )\n",
    "       downloaded += 1\n",
    "\n",
    "    with open(str(CACHE_DIR) + '/video_json/' + yt_id + '.json','w') as fp:\n",
    "        fp.write(json.dumps(result))\n",
    "    #pprint.pprint(result['upload_date'],result['view_count'])\n",
    "print('%s skipped and %s downloaded'%(skipped,downloaded))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87771fed-5233-45df-a9c7-c04bae5d25f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# this is to\n",
    "def get_assets_data():\n",
    "    # the file <root>/assets/data.js holds the category to video mappings\n",
    "    outstr = '['\n",
    "    data = {}\n",
    "    with open(PROJECT_DIR / 'assets/data.js', 'r') as fp:\n",
    "    #with open(OUTPUT_DIR + '/assets/data.js', 'r') as fp:\n",
    "        line = fp.readline()\n",
    "        while True:\n",
    "            if line.startswith('var') or not line :\n",
    "                if len(outstr) > 3:\n",
    "                    # clip off the trailing semicolon\n",
    "                    outstr = outstr[:-2]\n",
    "                    try:\n",
    "                        data[cat] = json.loads(outstr)\n",
    "                    except Exception:\n",
    "                        print('Parse error: %s'%outstr[:80])\n",
    "                        exit\n",
    "                cat = line[9:-4]\n",
    "                outstr = '['\n",
    "                if not line: break\n",
    "            else:\n",
    "                outstr += line\n",
    "            line = fp.readline()\n",
    "    return data\n",
    "\n",
    "zim_category_js = get_assets_data()\n",
    "# print(json.dumps(zim_category_js,indent=2))\n",
    "def get_zim_data(yt_id):\n",
    "    rtn_dict = {}\n",
    "    for cat in  iter(zim_category_js.keys()):\n",
    "        for video in range(len(zim_category_js[cat])):\n",
    "            if zim_category_js[cat][video]['id'] == yt_id:\n",
    "                rtn_dict = zim_category_js[cat][video]\n",
    "                break\n",
    "        if len(rtn_dict) > 0: break\n",
    "    return rtn_dict\n",
    "# ans = get_zim_data('usdJgEwMinM')\n",
    "# print(json.dumps(ans,indent=2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "847374a6-3628-4669-8b6e-1de356327cf7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# we need to ensure we have pymediainfo package installed inside the venv (pip3 install pymediainfo)\n",
    "# pymediainfo won't work coorectly if library libmediainfo0v5 is not installed (apt install libmediainfo0v5)\n",
    "from pprint import pprint\n",
    "from pymediainfo import MediaInfo\n",
    "\n",
    "def mediainfo_dict(path):\n",
    "    try:\n",
    "        minfo = MediaInfo.parse(path)\n",
    "    except:\n",
    "        print('mediainfo_dict. file not found: %s'%path)\n",
    "        return {}\n",
    "    return minfo.to_data()\n",
    "def select_info(path):\n",
    "    global data\n",
    "    data = mediainfo_dict(path)\n",
    "    rtn = {}\n",
    "    for index in range(len(data['tracks'])):\n",
    "        track = data['tracks'][index]\n",
    "        if track['kind_of_stream'] == 'General':\n",
    "            rtn['file_size'] = track.get('file_size',0)\n",
    "            rtn['bit_rate'] = track.get('overall_bit_rate',0)\n",
    "            rtn['time'] = track['other_duration'][0]\n",
    "        if track['kind_of_stream'] == 'Audio':\n",
    "            rtn['a_stream'] = track.get('stream_size',0)\n",
    "            rtn['a_rate'] = track.get('maximum_bit_rate',0)\n",
    "            rtn['a_channels'] = track.get('channel_s',0)\n",
    "        if track['kind_of_stream'] == 'Video':\n",
    "            rtn['v_stream'] = track.get('stream_size',0)\n",
    "            rtn['v_format'] = track['other_format'][0]\n",
    "            rtn['v_rate'] = track.get('bit_rate',0)\n",
    "            rtn['v_frame_rate'] = track.get('frame_rate',0)\n",
    "            rtn['v_width'] = track.get('width',0)\n",
    "            rtn['v_height'] = track.get('height',0)\n",
    "    return rtn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3f59ca9-0437-4674-98c1-d96845af2ca0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# the database created here can be found at ../working directory\n",
    "import sqlite3\n",
    "class Sqlite():\n",
    "   def __init__(self, filename):\n",
    "      self.conn = sqlite3.connect(filename)\n",
    "      self.conn.row_factory = sqlite3.Row\n",
    "      self.conn.text_factory = str\n",
    "      self.c = self.conn.cursor()\n",
    "    \n",
    "   def __del__(self):\n",
    "      self.conn.commit()\n",
    "      self.c.close()\n",
    "      del self.conn\n",
    "\n",
    "def get_video_json(path):\n",
    "    with open(path,'r') as fp:\n",
    "        try:\n",
    "            jsonstr = fp.read()\n",
    "            #print(path)\n",
    "            modules = json.loads(jsonstr.strip())\n",
    "        except Exception as e:\n",
    "            print(e)\n",
    "            print(jsonstr[:80])\n",
    "            return {}\n",
    "    return modules\n",
    "\n",
    "def video_size(yt_id):\n",
    "    return os.path.getsize(PROJECT_DIR + '/videos/' + yt_id + '/video.webm')\n",
    "\n",
    "def make_directory(path):\n",
    "    if not os.path.exists(path):\n",
    "        os.makedirs(path)\n",
    "\n",
    "def download_file(url,todir):\n",
    "    local_filename = url.split('/')[-1]\n",
    "    r = requests.get(url)\n",
    "    f = open(todir + '/' + local_filename, 'wb')\n",
    "    for chunk in r.iter_content(chunk_size=512 * 1024):\n",
    "        if chunk:\n",
    "            f.write(chunk)\n",
    "    f.close()\n",
    "    \n",
    "from datetime import datetime\n",
    "def age_in_years(upload_date):\n",
    "    uploaded_dt = datetime.strptime(upload_date,\"%Y%m%d\")\n",
    "    now_dt = datetime.now()\n",
    "    days_delta = now_dt - uploaded_dt\n",
    "    years = days_delta.days/365 + 1\n",
    "    return years"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df2f5fd3-bc3a-4915-91e0-ae1ffc9edb5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# erase the sql database (if already present inside ../working directory) if you want this script to reflect \n",
    "# the latest data\n",
    "def initialize_db():\n",
    "    sql = 'CREATE TABLE IF NOT EXISTS video_info ('\\\n",
    "            'yt_id TEXT UNIQUE, zim_size INTEGER, view_count INTEGER, age INTEGER, '\\\n",
    "            'views_per_year INTEGER, upload_date TEXT, duration TEXT, '\\\n",
    "            'height INTEGER, width INTEGER,'\\\n",
    "            'bit_rate TEXT, format TEXT, '\\\n",
    "            'average_rating REAL,slug TEXT,title TEXT)'\n",
    "    db.c.execute(sql)\n",
    "    \n",
    "print('Creating/Updating a Sqlite database with information about the Videos in this ZIM.')\n",
    "db = Sqlite(str(WORKING_DIR) + '/zim_video_info.sqlite')\n",
    "initialize_db()\n",
    "sql = 'select count() as num from video_info'\n",
    "db.c.execute(sql)\n",
    "row = db.c.fetchone()\n",
    "if row[0] == len(yt_id_list):\n",
    "    print('skipping update of sqlite database. Number of records equals number of videos')\n",
    "else:\n",
    "    for yt_id in iter(yt_id_list):\n",
    "        # some defaults\n",
    "        age = 0\n",
    "        views_per_year = 1\n",
    "        # fetch data from assets/data.js\n",
    "        zim_data = get_zim_data(yt_id)\n",
    "        if zim_data is not None:\n",
    "            if len(zim_data) == 0: \n",
    "                print('get_zim_data returned no data for %s'%yt_id)\n",
    "        slug = zim_data['slug']\n",
    "\n",
    "        # We already have youtube data for every video, use it \n",
    "        data = get_video_json(str(CACHE_DIR) + \"/video_json/\" + yt_id + '.json')\n",
    "        if data is not None:\n",
    "            if len(data) == 0:\n",
    "                print('get_video_json returned no data for %s'%yt_id)\n",
    "            vsize = data.get('filesize',0)\n",
    "            view_count = data.get('view_count',0)\n",
    "            upload_date = data.get('upload_date','')\n",
    "            average_rating = data.get('average_rating',0)\n",
    "            title = data.get('title','unknown title')\n",
    "        # calculate the views_per_year since it was uploaded\n",
    "        if upload_date != '':\n",
    "            age = round(age_in_years(upload_date))\n",
    "            views_per_year = int(view_count / age)\n",
    "\n",
    "        # interogate the video itself\n",
    "        filename = str(PROJECT_DIR) + '/videos/' + yt_id + '/video.webm'\n",
    "        if os.path.isfile(filename):\n",
    "            vsize = os.path.getsize(filename)\n",
    "            #print('vsize:%s'%vsize)\n",
    "            selected_data = select_info(filename)\n",
    "            if len(selected_data) == 0:\n",
    "                duration = \"not found\"\n",
    "                bit_rate = \"\" \n",
    "                v_format = \"\"\n",
    "            else:\n",
    "                duration = selected_data['time']\n",
    "                bit_rate = selected_data['bit_rate']\n",
    "                v_format = selected_data['v_format']\n",
    "                v_height = selected_data['v_height']\n",
    "                v_width = selected_data['v_width']\n",
    "\n",
    "        # colums names: yt_id,zim_size,view_count,views_per_year,upload_date,duration,\n",
    "        #         bit_rate, format,average_rating,slug\n",
    "        sql = 'INSERT OR REPLACE INTO video_info VALUES (?,?,?,?,?,?,?,?,?,?,?,?,?,?)'\n",
    "        db.c.execute(sql,[yt_id,vsize,view_count,round(age),views_per_year,upload_date, \\\n",
    "                          duration,v_height,v_width,bit_rate,v_format,average_rating,slug,title, ])\n",
    "    db.conn.commit()\n",
    "    print(yt_id,vsize,view_count,views_per_year,upload_date, \\\n",
    "                          duration,bit_rate,v_format,average_rating,slug,round(age))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef0bb27a-ec50-4b5e-bcbe-d76ecf99bef6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# this will output a table of all the videos sorted by views per year\n",
    "import pandas as pd\n",
    "from IPython.display import display \n",
    "global tot_sum\n",
    "\n",
    "def human_readable(num):\n",
    "    # return 3 significant digits and unit specifier\n",
    "    num = float(num)\n",
    "    units = [ '','K','M','G']\n",
    "    for i in range(4):\n",
    "        if num<10.0:\n",
    "            return \"%.2f%s\"%(num,units[i])\n",
    "        if num<100.0:\n",
    "            return \"%.1f%s\"%(num,units[i])\n",
    "        if num < 1000.0:\n",
    "            return \"%.0f%s\"%(num,units[i])\n",
    "        num /= 1024.0\n",
    "\n",
    "sql = 'select slug,zim_size,views_per_year,view_count,duration,upload_date,'\\\n",
    "       'bit_rate from video_info order by views_per_year desc'\n",
    "tot_sum = 0\n",
    "db.c.execute(sql)\n",
    "rows = db.c.fetchall()\n",
    "row_list = []\n",
    "boundary_views_per_year = 0\n",
    "for row in rows:\n",
    "    tot_sum += row['zim_size']\n",
    "    row_list.append([row['slug'][:60],human_readable(row['zim_size']),\\\n",
    "                              human_readable(tot_sum),human_readable(row['view_count']),\\\n",
    "                              human_readable(row['views_per_year']),\\\n",
    "                              row['upload_date'],row['duration'],row['bit_rate']])\n",
    "    if tot_sum > TARGET_SIZE and boundary_views_per_year == 0:\n",
    "        boundary_views_per_year = row['views_per_year']\n",
    "sql = 'select slug,zim_size,views_per_year,view_count,duration,upload_date,'\\\n",
    "       'format,width,height,bit_rate from video_info order by views_per_year desc'\n",
    "db.c.execute(sql)\n",
    "rows = db.c.fetchall()\n",
    "print('%60s %6s %6s %6s %6s %8s %8s'%('Name','Size','Sum','Views','Views','Date  ','Duration'))\n",
    "print('%60s %6s %6s %6s %6s %8s %8s'%('','','','','/ yr','',''))\n",
    "tot_sum = 0\n",
    "for row in rows:\n",
    "    tot_sum += row['zim_size']\n",
    "    print('%60s %6s %6s %6s %6s %8s %8s'%(row['slug'][:60],human_readable(row['zim_size']),\\\n",
    "                              human_readable(tot_sum),human_readable(row['view_count']),\\\n",
    "                              human_readable(row['views_per_year']),\\\n",
    "                              row['upload_date'],row['duration']))\n",
    "#df = pd.read_sql(sql,db.conn)\n",
    "#df = pd.DataFrame(row_list,columns=['Name','Size','Sum','Views','Views','Date','Duration','Bit Rate'])\n",
    "#display(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df9ee276-73a2-4643-884e-5af915860480",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('We will include videos with views_per_year greater than %s'%boundary_views_per_year)\n",
    "wanted_ids = []\n",
    "sql = 'SELECT yt_id, title from video_info where views_per_year > ?'\n",
    "db.c.execute(sql,[boundary_views_per_year,])\n",
    "rows = db.c.fetchall()\n",
    "#for row in rows:\n",
    "   # print(row['yt_id'])\n",
    " #   wanted_ids.append(row['yt_id'])\n",
    "\n",
    "with open(str(NEW_ZIM_DIR) + '/wanted_list.csv','w') as fp:\n",
    "    for row in rows:\n",
    "        fp.write('%s,%s\\n'%(row['yt_id'],row['title'],))\n",
    "        wanted_ids.append(row['yt_id'])\n",
    "        print(row['yt_id'])\n",
    "  #  with open(HOME + '/zimtest/' + PROJECT_NAME + '/wanted_list.csv','w') as fp:\n",
    "#    for row in rows:\n",
    "#        fp.write('%s,%s\\n'%(row['yt_id'],row['title'],))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "798b293c-c25d-42da-bb19-58982b7e81c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import shutil\n",
    "# copy the default top level directories (these were in the zim's \"-\" directory - old zim format)\n",
    "print('Copying wanted folders and Videos to %s'%OUTPUT_DIR)\n",
    "cpy_dirs = ['assets','cache','channels']\n",
    "for d in cpy_dirs:\n",
    "    shutil.rmtree(os.path.join(OUTPUT_DIR,d),ignore_errors=True)\n",
    "    os.makedirs(os.path.join(OUTPUT_DIR,d))\n",
    "    src = os.path.join(PROJECT_DIR,d)\n",
    "    dest = os.path.join(OUTPUT_DIR,d)\n",
    "    shutil.copytree(src,dest,dirs_exist_ok=True, symlinks=True)\n",
    "    print(dest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c825db16-a49b-4c74-80d1-a9661710c1f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Copy the videos selected by the wanted_ids list to output file\n",
    "import shutil\n",
    "for f in wanted_ids:\n",
    "    if not os.path.isdir(os.path.join(OUTPUT_DIR,'videos',f)):\n",
    "        os.makedirs(os.path.join(OUTPUT_DIR,'videos',f))\n",
    "        src = os.path.join(PROJECT_DIR,'videos',f)\n",
    "        dest = os.path.join(OUTPUT_DIR,'videos',f)\n",
    "        shutil.copytree(src,dest,dirs_exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c84a54e8-2d56-4053-87ed-36b7c677bf3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#  Copy the files in the root directory\n",
    "import shutil\n",
    "for yt_id in wanted_ids:\n",
    "    # print(yt_id)\n",
    "    map_index_to_slug = get_zim_data(yt_id)\n",
    "    # print(len(map_index_to_slug))\n",
    "    if len(map_index_to_slug) > 0:\n",
    "        title = map_index_to_slug['slug']\n",
    "        src = os.path.join(PROJECT_DIR,title + '.html')\n",
    "        # print(src)\n",
    "        dest = str(OUTPUT_DIR) + '/' + title + '.html'\n",
    "        if os.path.isfile(src) and not os.path.isfile(dest):\n",
    "            shutil.copyfile(src,dest)\n",
    "           # print('moving:', src)\n",
    "        else:\n",
    "            print('src:%s'%src)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d10bce02-905c-476f-872d-61f8ed2c8900",
   "metadata": {},
   "outputs": [],
   "source": [
    "# There are essential files that are needed in the zim\n",
    "needed = ['/favicon.jpg','/home.html','/profile.jpg','/banner.jpg','/metadata.json']\n",
    "for f in needed:\n",
    "    cmd = '/bin/cp %s %s'%(str(PROJECT_DIR)  + f,str(OUTPUT_DIR))\n",
    "    subprocess.run(cmd,shell=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0731c2a2-9b18-450e-9e45-fece3481f004",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write a new mapping from categories to videos (with some removed)\n",
    "print('Creating a new mapping from Categories to videos within each category.')\n",
    "outstr = ''\n",
    "for cat in zim_category_js:\n",
    "    outstr += 'var json_%s = [\\n'%cat\n",
    "    for video in range(len(zim_category_js[cat])):\n",
    "        if zim_category_js[cat][video].get('id','') in wanted_ids:\n",
    "            outstr += json.dumps(zim_category_js[cat][video],indent=1)\n",
    "            outstr += ','\n",
    "    outstr = outstr[:-1]\n",
    "    outstr += '];\\n'\n",
    "with open(str(OUTPUT_DIR) + '/assets/data.js','w') as fp:\n",
    "    fp.write(outstr)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22430f92-79c8-4678-8d3e-b5e5bce20e7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# install zimscraperlib (pip3 install zimscraperlib) and libzim library before running this\n",
    "print('Creating a new ZIM and Indexing it')\n",
    "\n",
    "import os\n",
    "from pathlib import Path\n",
    "from zimscraperlib.zim import make_zim_file\n",
    "from glob import glob\n",
    "from datetime import datetime\n",
    "\n",
    "# original_name = \"climate_and_energy_2023-02.zim\"\n",
    "# print(original_name)\n",
    "fname = \"0223-crashcourse_en_top1g_2023-02.zim\"\n",
    "print('fname:%s'%fname)\n",
    "#sys.exit(1)\n",
    "\n",
    "os.chdir(OUTPUT_DIR)\n",
    "if not os.path.isfile(os.path.join(NEW_ZIM_DIR,fname)):\n",
    "    make_zim_file(\n",
    "        build_dir=OUTPUT_DIR,\n",
    "        fpath=NEW_ZIM_DIR / fname,\n",
    "        name=fname,\n",
    "        main_page=\"home.html\",\n",
    "        favicon=\"favicon.jpg\",\n",
    "        title=\"CrashCourse\",\n",
    "        description=\"CrashCourse top videos (1GB)\",\n",
    "        language=\"en\",\n",
    "        creator=\"CrashCourse\",\n",
    "        publisher=\"Internet in a Box\",\n",
    "        tags=\"test\",\n",
    "        scraper=\"zimscraperlib\",\n",
    "            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44f1a98c-8653-427f-afb6-1d2722168b3a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
